{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5 (Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Autorin: Anna (i3-Versicherung)\n",
    "* Webseite: [Data Science Training - Kapitel 20](https://data-science.training/kapitel-20/)\n",
    "* Datum: 23.03.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datenversion: 9\n",
    "\n",
    "Methode: Gradient Boosting (GB)\n",
    "\n",
    "Optimierung: Ergebnis von Halving Random Search (HRS)\n",
    "\n",
    "Schwellenwerte: 0.70, 0.75, 0.80, 0.85, 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Paket (Package) importieren\n",
    "#  Datenstrukturen und Datenanalyse, I/O\n",
    "#  https://pandas.pydata.org/pandas-docs/stable/\n",
    "import pandas as pd\n",
    "# NumPy Paket (Package) importieren\n",
    "#  Mehrdimensionale Datenstrukturen (Vektoren, Matrizen, Tensoren, Arrays), Lineare Algebra\n",
    "#  https://numpy.org/doc/\n",
    "import numpy as np\n",
    "# Pickle Paket (Package) importieren\n",
    "#  Objekte serialisieren\n",
    "#  https://docs.python.org/3/library/pickle.html\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenversion festlegen: 9\n",
    "version   = 9\n",
    "# Modell-Abkürzung festlegen: gb = Gradient Boosting\n",
    "shortcut  = 'gb'\n",
    "# Optimierungsart festlegen: hrs = Halving Random Search\n",
    "opt       = 'hrs'\n",
    "# Optimalen Schwellenwert festlegen: 0.70, 0.75, 0.80, 0.85, 0.90\n",
    "threshold = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testdaten als Pandas Data Frame (df) aus Excel-Datei laden\n",
    "#  (KNIME: \"Excel Reader\")\n",
    "filename = '../../data/titanic/new/test_v' + str(version) + '.xlsx'\n",
    "df_test  = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell laden\n",
    "#  (KNIME: \"PMML Reader\")\n",
    "filename = '../../models/titanic/new/' + shortcut + '_v' + str(version) + '_' + opt + '_thr_' + str(threshold)\n",
    "model = pk.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testdaten: Daten ohne PassengerId extrahieren\n",
    "X_test = df_test.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wahrscheinlichkeiten bestimmen\n",
    "#  (KNIME: \"XYZ Predictor\")\n",
    "y_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prognosen aus den Klassen-Wahrscheinlichkeiten mittels Schwellenwert berechnen\n",
    "def dst_predictions(y_prob, threshold=0.5):\n",
    "    m = len(y_prob[:,1])\n",
    "    y_pred = np.zeros(m)\n",
    "    for k in range(0, m):\n",
    "        if y_prob[k][1] > threshold:\n",
    "            y_pred[k] = 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prognosen berechnen\n",
    "#  (KNIME: \"XYZ Predictor\")\n",
    "y_pred = dst_predictions(y_prob, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnisse in das Data Frame kopieren\n",
    "df_test['Survived'] = y_pred\n",
    "df_test['ProbN']    = y_prob[:,0]\n",
    "df_test['ProbP']    = y_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevante Ergebnisse filtern\n",
    "#  (KNIME: \"Column Filter\")\n",
    "df_res = df_test.filter(['PassengerId', 'Survived', 'ProbN', 'ProbP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnisse als CSV-Datei speichern\n",
    "#  (KNIME: \"CSV Writer\")\n",
    "filename = '../../data/titanic/submission/' + shortcut + '_v' + str(version) + '_' + opt + '_thr_' + str(threshold) + '.csv'\n",
    "df_res.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnis-Datei auf Webseite hochladen\n",
    "# https://data-science.training/upload/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnisse (Gütemaße)\n",
    "\n",
    "#### Schwelle = 0,70\n",
    "\n",
    "* Genauigkeit \t(Accuracy) \t: \t75,84 \t%\n",
    "* Spezifität \t(Specificity) \t: \t93,08 \t%\n",
    "* Sensitivität \t(Sensitivity) \t: \t47,47 \t%\n",
    "* Präzision \t(Precision) \t: \t80,65 \t%\n",
    "* Recall \t(Recall) \t: \t47,47 \t%\n",
    "* F-Maß \t(F1 Score) \t: \t59,76 \t%\n",
    "* AURC \t(AURC) \t: \t82,35 \t%\n",
    "* LogLoss \t(LogLoss) \t: \t0,487\n",
    "\n",
    "#### Schwelle = 0,75\n",
    "\n",
    "* Genauigkeit \t(Accuracy) \t: \t76,56 \t%\n",
    "* Spezifität \t(Specificity) \t: \t95,38 \t%\n",
    "* Sensitivität \t(Sensitivity) \t: \t45,57 \t%\n",
    "* Präzision \t(Precision) \t: \t85,71 \t%\n",
    "* Recall \t(Recall) \t: \t45,57 \t%\n",
    "* F-Maß \t(F1 Score) \t: \t59,50 \t%\n",
    "* AURC \t(AURC) \t: \t82,35 \t%\n",
    "* LogLoss \t(LogLoss) \t: \t0,487\n",
    "\n",
    "#### Schwelle = 0,80\n",
    "\n",
    "* Genauigkeit \t(Accuracy) \t: \t76,56 \t%\n",
    "* Spezifität \t(Specificity) \t: \t97,69 \t%\n",
    "* Sensitivität \t(Sensitivity) \t: \t41,77 \t%\n",
    "* Präzision \t(Precision) \t: \t<span style=\"color:red\">91,67 \t%</span>\n",
    "* Recall \t(Recall) \t: \t41,77 \t%\n",
    "* F-Maß \t(F1 Score) \t: \t57,39 \t%\n",
    "* AURC \t(AURC) \t: \t82,35 \t%\n",
    "* LogLoss \t(LogLoss) \t: \t0,487\n",
    "\n",
    "#### Schwelle = 0,85\n",
    "\n",
    "* Genauigkeit \t(Accuracy) \t: \t72,97 \t%\n",
    "* Spezifität \t(Specificity) \t: \t98,08 \t%\n",
    "* Sensitivität \t(Sensitivity) \t: \t31,65 \t%\n",
    "* Präzision \t(Precision) \t: \t<span style=\"color:red\">90,91 \t%</span>\n",
    "* Recall \t(Recall) \t: \t31,65 \t%\n",
    "* F-Maß \t(F1 Score) \t: \t46,95 \t%\n",
    "* AURC \t(AURC) \t: \t82,35 \t%\n",
    "* LogLoss \t(LogLoss) \t: \t0,487\n",
    "\n",
    "#### Schwelle = 0,90\n",
    "\n",
    "* Genauigkeit \t(Accuracy) \t: \t71,05 \t%\n",
    "* Spezifität \t(Specificity) \t: \t99,23 \t%\n",
    "* Sensitivität \t(Sensitivity) \t: \t24,68 \t%\n",
    "* Präzision \t(Precision) \t: \t<span style=\"color:red\">95,12 \t%</span>\n",
    "* Recall \t(Recall) \t: \t24,68 \t%\n",
    "* F-Maß \t(F1 Score) \t: \t39,20 \t%\n",
    "* AURC \t(AURC) \t: \t82,35 \t%\n",
    "* LogLoss \t(LogLoss) \t: \t0,487\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
